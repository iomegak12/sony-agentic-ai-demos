{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Service Support Agent - Multi-Agent Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.5, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the Product QnA Agent\n",
    "%run \"1-product-agent.ipynb\" \n",
    "print(\"===============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_QnA_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the orders agents\n",
    "%run \"2-order-agent.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "# Helper function to invoke an agent\n",
    "def agent_node(state, agent, name, config):\n",
    "\n",
    "    #extract thread-id from request for conversation memory\n",
    "    thread_id=config[\"metadata\"][\"thread_id\"]\n",
    "    #Set the config for calling the agent\n",
    "    agent_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    #Pass the thread-id to establish memory for chatbot\n",
    "    #Invoke the agent with the state\n",
    "    result = agent.invoke(state, agent_config)\n",
    "\n",
    "    # Convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        final_result=AIMessage(result['messages'][-1].content)\n",
    "    return {\n",
    "        \"messages\": [final_result]\n",
    "    }\n",
    "\n",
    "#Create the product QnA node\n",
    "product_QnA_node=functools.partial(agent_node, \n",
    "                                   agent=product_QnA_agent, \n",
    "                                   name=\"Product_QnA_Agent\")\n",
    "#Create the Orders node\n",
    "#For a custom agent, the agent graph need to be provided as input\n",
    "orders_node=functools.partial(agent_node,\n",
    "                              agent=orders_agent.agent_graph,\n",
    "                              name=\"Orders_Agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the routing agent\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "import operator\n",
    "\n",
    "class RouterAgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class RouterAgent:\n",
    "\n",
    "    def __init__(self, model, system_prompt, smalltalk_prompt, debug=False):\n",
    "        \n",
    "        self.system_prompt=system_prompt\n",
    "        self.smalltalk_prompt=smalltalk_prompt\n",
    "        self.model=model\n",
    "        self.debug=debug\n",
    "        \n",
    "        router_graph=StateGraph(RouterAgentState)\n",
    "        router_graph.add_node(\"Router\",self.call_llm)\n",
    "        router_graph.add_node(\"Product_Agent\",product_QnA_node)\n",
    "        router_graph.add_node(\"Orders_Agent\",orders_node)\n",
    "        router_graph.add_node(\"Small_Talk\", self.respond_smalltalk)\n",
    "                              \n",
    "        router_graph.add_conditional_edges(\n",
    "            \"Router\",\n",
    "            self.find_route,\n",
    "            {\"PRODUCT\": \"Product_Agent\", \n",
    "             \"ORDER\" : \"Orders_Agent\",\n",
    "             \"SMALLTALK\" : \"Small_Talk\",\n",
    "             \"END\": END }\n",
    "        )\n",
    "\n",
    "        #One way routing, not coming back to router\n",
    "        router_graph.add_edge(\"Product_Agent\",END)\n",
    "        router_graph.add_edge(\"Orders_Agent\",END)\n",
    "        router_graph.add_edge(\"Small_Talk\",END)\n",
    "        \n",
    "        #Set where there graph starts\n",
    "        router_graph.set_entry_point(\"Router\")\n",
    "        self.router_graph = router_graph.compile()\n",
    "\n",
    "    def call_llm(self, state:RouterAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "        if self.debug:\n",
    "            print(f\"Call LLM received {messages}\")\n",
    "            \n",
    "        #If system prompt exists, add to messages in the front\n",
    "        if self.system_prompt:\n",
    "            messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "\n",
    "        #invoke the model with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Call LLM result {result}\")\n",
    "        return { \"messages\":[result] }\n",
    "\n",
    "    def respond_smalltalk(self, state:RouterAgentState):\n",
    "        messages=state[\"messages\"]\n",
    "        if self.debug:\n",
    "            print(f\"Small talk received: {messages}\")\n",
    "            \n",
    "        #If system prompt exists, add to messages in the front\n",
    "        \n",
    "        messages = [SystemMessage(content=self.smalltalk_prompt)] + messages\n",
    "\n",
    "        #invoke the model with the message history\n",
    "        result = self.model.invoke(messages)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Small talk result {result}\")\n",
    "        return { \"messages\":[result] }\n",
    "        \n",
    "    def find_route(self, state:RouterAgentState):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if self.debug: \n",
    "            print(\"Router: Last result from LLM : \", last_message)\n",
    "\n",
    "        #Set the last message as the destination\n",
    "        destination=last_message.content\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Destination chosen : {destination}\")\n",
    "        return destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the chatbot\n",
    "from IPython.display import Image\n",
    "\n",
    "#Setup the system problem\n",
    "system_prompt = \"\"\" \n",
    "You are a Router, that analyzes the input query and chooses 4 options:\n",
    "SMALLTALK: If the user input is small talk, like greetings and good byes.\n",
    "PRODUCT: If the query is a product question about laptops, like features, specifications and pricing.\n",
    "ORDER: If the query is about orders for laptops, like order status, order details or update order quantity\n",
    "END: Default, when its neither PRODUCT or ORDER.\n",
    "\n",
    "The output should only be just one word out of the possible 4 : SMALLTALK, PRODUCT, ORDER, END.\n",
    "\"\"\"\n",
    "\n",
    "smalltalk_prompt=\"\"\"\n",
    "If the user request is small talk, like greetings and goodbyes, respond professionally.\n",
    "Mention that you will be able to answer questions about laptop product features and provide order status and updates.\n",
    "\"\"\"\n",
    "\n",
    "router_agent = RouterAgent(model, \n",
    "                           system_prompt, \n",
    "                           smalltalk_prompt,\n",
    "                           debug=False)\n",
    "\n",
    "Image(router_agent.router_graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute a single request\n",
    "messages=[HumanMessage(content=\"Tell me about the features of SpectraBook\")]\n",
    "result=router_agent.router_graph.invoke({\"messages\":messages},config)\n",
    "\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute a single request\n",
    "messages=[HumanMessage(content=\"What is the status of order ORD-7311?\")]\n",
    "\n",
    "result=router_agent.router_graph.invoke({\"messages\":messages},config)\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "user_inputs = [\n",
    "    \"How are you doing?\",\n",
    "    \"Please show me the details of the order ORD-7311\",\n",
    "    \"Can you add one more of that laptop to the order? \",\n",
    "    \"Tell me about the features of SpectraBook laptop\",\n",
    "    \"How much does it cost?\",\n",
    "    \"Bye\"\n",
    "]\n",
    "\n",
    "#Create a new thread\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "for input in user_inputs:\n",
    "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
    "    #Format the user message\n",
    "    user_message = {\"messages\":[HumanMessage(input)]}\n",
    "    #Get response from the agent\n",
    "    ai_response = router_agent.router_graph.invoke(user_message,config=config)\n",
    "    #Print the response\n",
    "    print(f\"\\nAGENT : {ai_response['messages'][-1].content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
