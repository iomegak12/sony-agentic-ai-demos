{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.5, max_tokens=1000)\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "#Load the laptop product pricing CSV into a Pandas dataframe.\n",
    "product_pricing_df = pd.read_csv(\"data/Laptop pricing.csv\")\n",
    "print(product_pricing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_laptop_price(laptop_name:str) -> int :\n",
    "    \"\"\"\n",
    "    This function returns the price of a laptop, given its name as input.\n",
    "    It performs a substring match between the input name and the laptop name.\n",
    "    If a match is found, it returns the pricxe of the laptop.\n",
    "    If there is NO match found, it returns -1\n",
    "    \"\"\"\n",
    "\n",
    "    #Filter Dataframe for matching names\n",
    "    match_records_df = product_pricing_df[\n",
    "                        product_pricing_df[\"Name\"].str.contains(\n",
    "                                                \"^\" + laptop_name, case=False)\n",
    "                        ]\n",
    "    #Check if a record was found, if not return -1\n",
    "    if len(match_records_df) == 0 :\n",
    "        return -1\n",
    "    else:\n",
    "        return match_records_df[\"Price\"].iloc[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the tool. Before running the test, comment the @tool annotation\n",
    "# print(get_laptop_price(\"alpha\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_laptop_price(\"testing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_chroma import Chroma \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the product featuers document.\n",
    "loader=PyPDFLoader(\"./data/Laptop product descriptions.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "#Create a vector store with Chroma\n",
    "prod_feature_store = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "get_product_features = create_retriever_tool(\n",
    "    prod_feature_store.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    name=\"Get_Product_Features\",\n",
    "    description=\"\"\"\n",
    "    This store contains details about Laptops. It lists the available laptops\n",
    "    and their features including CPU, memory, storage, design and advantages\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prod_feature_store.as_retriever().invoke(\"Tell me about the AlphaBook Pro\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "\n",
    "#Create a System prompt to provide a persona to the chatbot\n",
    "system_prompt = SystemMessage(\"\"\"\n",
    "    You are professional chatbot that answers questions about laptops sold by your company.\n",
    "    To answer questions about laptops, you will ONLY use the available tools and NOT your own memory.\n",
    "    You will handle small talk and greetings by producing professional responses.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#Create a list of tools available\n",
    "tools = [get_laptop_price, get_product_features]\n",
    "\n",
    "#Create memory across questions in a conversation (conversation memory)\n",
    "checkpointer=MemorySaver()\n",
    "\n",
    "#Create a Product QnA Agent. This is actual a graph in langGraph\n",
    "product_QnA_agent=create_react_agent(\n",
    "                                model=model, #LLM to use\n",
    "                                tools=tools, #List of tools to use\n",
    "                                state_modifier=system_prompt, #The system prompt\n",
    "                                debug=False, #Debugging turned on if needed\n",
    "                                checkpointer=checkpointer #For conversation memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup chatbot\n",
    "import uuid\n",
    "#To maintain memory, each request should be in the context of a thread.\n",
    "#Each user conversation will use a separate thread ID\n",
    "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "\n",
    "#Test the agent with an input\n",
    "inputs = {\"messages\":[\n",
    "                HumanMessage(\"What are the features and pricing for GammaAir?\")\n",
    "            ]}\n",
    "\n",
    "#Use streaming to print responses as the agent  does the work.\n",
    "#This is an alternate way to stream agent responses without waiting for the agent to finish\n",
    "for stream in product_QnA_agent.stream(inputs, config, stream_mode=\"values\"):\n",
    "    message=stream[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "#Send a sequence of messages to chatbot and get its response\n",
    "#This simulates the conversation between the user and the Agentic chatbot\n",
    "user_inputs = [\n",
    "    \"Hello\",\n",
    "    \"I am looking to buy a laptop\",\n",
    "    \"Give me a list of available laptop names\",\n",
    "    \"Tell me about the features of  SpectraBook\",\n",
    "    \"How much does it cost?\",\n",
    "    \"Give me similar information about OmegaPro\",\n",
    "    \"What info do you have on AcmeRight ?\",\n",
    "    \"Thanks for the help\"\n",
    "]\n",
    "\n",
    "#Create a new thread\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "for input in user_inputs:\n",
    "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
    "    #Format the user message\n",
    "    user_message = {\"messages\":[HumanMessage(input)]}\n",
    "    #Get response from the agent\n",
    "    ai_response = product_QnA_agent.invoke(user_message,config=config)\n",
    "    #Print the response\n",
    "    print(f\"AGENT : {ai_response['messages'][-1].content}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
