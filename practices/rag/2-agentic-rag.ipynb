{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"GoogleSearch\")\n",
    "def search(query_string: str):\n",
    "    \"\"\"\n",
    "    Useful to search for any kinds of information and\n",
    "    when you need to search the internet for any kinds of information, use this tool.\n",
    "    Prefer this tool when you search for long queries.\n",
    "    Should not be used for Article search.\n",
    "    \"\"\"\n",
    "    \n",
    "    search = GoogleSerperAPIWrapper()\n",
    "    \n",
    "    return search.run(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    "wiki = WikipediaQueryRun(\n",
    "    name=\"WikiepdiaSearch\",\n",
    "    description=\"Use this tool when you want to search for information on Wikipedia by Terms, Keywords or any Topics.\",\n",
    "    api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WikiepdiaSearch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ").split_documents(docs)\n",
    "\n",
    "vectordatabase = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordatabase.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000016390718820>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"search for information about langsmith. for any questions related to langsmith, you must use this tool\"\n",
    ")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=1000)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=1000)),\n",
       " StructuredTool(name='GoogleSearch', description='Useful to search for any kinds of information and\\nwhen you need to search the internet for any kinds of information, use this tool.\\nPrefer this tool when you search for long queries.', args_schema=<class 'langchain_core.utils.pydantic.GoogleSearch'>, func=<function search at 0x00000163F5A70430>),\n",
       " WikipediaQueryRun(name='WikiepdiaSearch', description='Use this tool when you want to search for information on Wikipedia by Terms, Keywords or any Topics.', api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\jdram\\\\.pyenv\\\\pyenv-win\\\\versions\\\\3.10.5\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=1000)),\n",
       " Tool(name='langsmith_search', description='search for information about langsmith. for any questions related to langsmith, you must use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000163F7B0A050>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000016390718820>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000163F7E98040>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000016390718820>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [arxiv, search, wiki, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.1,\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdram\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "# agent = create_react_agent(llm = llm, tools = tools, prompt=prompt)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "agent_executor = create_react_agent(\n",
    "    llm,\n",
    "    tools = tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hOxBxEf9ywgHAiC1BFlX5DlL', 'function': {'arguments': '{\"query\":\"langsmith\"}', 'name': 'langsmith_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 252, 'total_tokens': 269, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChT9s0j8WIBwLT5n4uQfKdbtDRdF', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-624922c7-5bd9-4afb-ae88-45f204e9cf98-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'langsmith'}, 'id': 'call_hOxBxEf9ywgHAiC1BFlX5DlL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 252, 'output_tokens': 17, 'total_tokens': 269, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n",
      "{'tools': {'messages': [ToolMessage(content=\"Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\nLangSmith + LangChain OSSLangSmith is framework-agnostic ‚Äî\\xa0it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\\nFor more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\nObservability\\u200b\\nObservability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\\nThis is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\\nLangSmith is a platform for building production-grade LLM applications.\\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\nObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic ‚Äî score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\\n\\nGet started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\", name='langsmith_search', id='a02a3219-d738-4860-8595-ef21f88a0a89', tool_call_id='call_hOxBxEf9ywgHAiC1BFlX5DlL')]}}\n",
      "***********\n",
      "{'agent': {'messages': [AIMessage(content='LangSmith is a platform for building production-grade Large Language Models (LLM) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith provides observability features, allowing you to analyze traces, configure metrics, dashboards, and alerts based on these. It also offers evaluation capabilities to assess application performance over production traffic and gather human feedback on data. Additionally, LangSmith supports prompt engineering, providing tools for writing prompts to instruct the LLM on what to do.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 834, 'total_tokens': 941, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTBxXx6Piwtzn6bnEjBpa21VbZL', 'finish_reason': 'stop', 'logprobs': None}, id='run-d47c9da7-8557-4079-bde5-30f4171fe9c8-0', usage_metadata={'input_tokens': 834, 'output_tokens': 107, 'total_tokens': 941, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "for stream in agent_executor.stream({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"tell me about langsmith\")\n",
    "    ]\n",
    "}):\n",
    "    print(stream)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zpoG07UmFsc6HqzhHJKJlEz9', 'function': {'arguments': '{\"query\":\"2412.16446\"}', 'name': 'arxiv'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 261, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTCSjQPOyPvFOzPZOVG1aLnAU3r', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-896dad32-95ec-4fc7-aca0-cbdab10ac072-0', tool_calls=[{'name': 'arxiv', 'args': {'query': '2412.16446'}, 'id': 'call_zpoG07UmFsc6HqzhHJKJlEz9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 261, 'output_tokens': 19, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n",
      "{'tools': {'messages': [ToolMessage(content='Published: 2024-12-21\\nTitle: Sensitive Image Classification by Vision Transformers\\nAuthors: Hanxian He, Campbell Wilson, Thanh Thi Nguyen, Janis Dalins\\nSummary: When it comes to classifying child sexual abuse images, managing similar\\ninter-class correlations and diverse intra-class correlations poses a\\nsignificant challenge. Vision transformer models, unlike conventional deep\\nconvolutional network models, leverage a self-attention mechanism to capture\\nglobal interactions among contextual local elements. This allows them to\\nnavigate through image patches effectively, avoiding incorrect correlations and\\nreducing ambiguity in attention maps, thus proving their efficacy in computer\\nvision tasks. Rather than directly analyzing child sexual abuse data, we\\nconstructed two datasets: one comprising clean and pornographic images and\\nanother with three classes, which additionally include images indicative of\\npornography, sourced from Reddit and Google Open Images data. In our\\nexperiments, we also', name='arxiv', id='4e9c5e49-4c0a-4464-8579-df1beec7835b', tool_call_id='call_zpoG07UmFsc6HqzhHJKJlEz9')]}}\n",
      "***********\n",
      "{'agent': {'messages': [AIMessage(content='The paper with identifier 2412.16446 is titled \"Sensitive Image Classification by Vision Transformers.\" It discusses the challenges in classifying child sexual abuse images due to inter-class correlations and diverse intra-class correlations. The paper explores the use of vision transformer models, which leverage a self-attention mechanism to capture global interactions among contextual local elements in images. These models are effective in computer vision tasks by avoiding incorrect correlations and reducing ambiguity in attention maps. The study constructed datasets with clean, pornographic, and indicative pornography images sourced from Reddit and Google Open Images data for experimentation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 477, 'total_tokens': 593, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTEP4JnMAgUxp5wXzbEdjVdYn2l', 'finish_reason': 'stop', 'logprobs': None}, id='run-349111c6-14f3-4480-ba45-a7ea545a666e-0', usage_metadata={'input_tokens': 477, 'output_tokens': 116, 'total_tokens': 593, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "for stream in agent_executor.stream({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"whats the paper 2412.16446 talk about it?\")\n",
    "    ]\n",
    "}):\n",
    "    print(stream)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_urhGwJujEjyvud3nlAKSLdbz', 'function': {'arguments': '{\"query\": \"Machine Learning\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_m6UIK7qWWMkesNmwZhOTJ0Vk', 'function': {'arguments': '{\"query_string\": \"Machine Learning\"}', 'name': 'GoogleSearch'}, 'type': 'function'}, {'id': 'call_nXzqff055BR439R45zX83Idp', 'function': {'arguments': '{\"query\": \"Machine Learning\"}', 'name': 'WikiepdiaSearch'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 249, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTG0fXOefZR7JwWFfoh3D9IF6td', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b620c80f-0b20-40ea-ace1-4a31b6e28afd-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Machine Learning'}, 'id': 'call_urhGwJujEjyvud3nlAKSLdbz', 'type': 'tool_call'}, {'name': 'GoogleSearch', 'args': {'query_string': 'Machine Learning'}, 'id': 'call_m6UIK7qWWMkesNmwZhOTJ0Vk', 'type': 'tool_call'}, {'name': 'WikiepdiaSearch', 'args': {'query': 'Machine Learning'}, 'id': 'call_nXzqff055BR439R45zX83Idp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 249, 'output_tokens': 66, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n",
      "{'tools': {'messages': [ToolMessage(content='Published: 2019-09-08\\nTitle: Lecture Notes: Optimization for Machine Learning\\nAuthors: Elad Hazan\\nSummary: Lecture notes on optimization for machine learning, derived from a course at\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\nSimons Foundation, Berkeley.', name='arxiv', id='003e2d0d-6f88-4cec-bb29-b0b3b88f9f44', tool_call_id='call_urhGwJujEjyvud3nlAKSLdbz'), ToolMessage(content=\"Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from ... Machine learning (ML) is a branch of artificial intelligence (AI) focused on enabling computers and machines to imitate the way that humans learn, ... Google's fast-paced, practical introduction to machine learning, featuring a series of lessons with video lectures, interactive visualizations, and hands-on ... Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed. ‚ÄúIn ... Machine learning, a subset of Artificial Intelligence, enables computers to learn from data and make predictions through various techniques ... Build & train supervised machine learning models for prediction & binary classification tasks, including linear regression & logistic regression. Azure Machine Learning allows us to build machine learning solutions that can scale and give customers the right offers and better service overall. Machine learning is a field of study of artificial intelligence (AI) which allows machines to be more intelligent without human intervention , i.e., it gives ... Machine learning is a subset of artificial intelligence that trains a machine how to learn. See how machine learning works and how it's being used today.\", name='GoogleSearch', id='436dd4dd-f3e2-44e8-b3da-49ca935e888b', tool_call_id='call_m6UIK7qWWMkesNmwZhOTJ0Vk'), ToolMessage(content='Page: Machine learning\\nSummary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning. \\nFrom a theoretical viewpoint, probab', name='WikiepdiaSearch', id='650dd542-2c2f-492f-a929-593a2bce6aea', tool_call_id='call_nXzqff055BR439R45zX83Idp')]}}\n",
      "***********\n",
      "{'agent': {'messages': [AIMessage(content=\"### Machine Learning\\n\\n#### Arxiv.org Search Results:\\n- **Title:** Lecture Notes: Optimization for Machine Learning\\n- **Authors:** Elad Hazan\\n- **Summary:** Lecture notes on optimization for machine learning, derived from a course at Princeton University and tutorials given in MLSS, Buenos Aires, as well as Simons Foundation, Berkeley.\\n\\n#### Google Search Results:\\n- Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\\n- Machine learning is a subfield of artificial intelligence that gives computers the ability to learn without explicitly being programmed.\\n- Google's fast-paced, practical introduction to machine learning, featuring a series of lessons with video lectures, interactive visualizations, and hands-on activities.\\n\\n#### Wikipedia Search Results:\\n- Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\\n- Advances in the field of deep learning have allowed neural networks to surpass many previous machine learning approaches in performance.\\n- ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.\\n\\nMachine learning is a subset of artificial intelligence that enables computers to learn from data and make predictions through various techniques. It has applications in a wide range of fields and is a key component of predictive analytics.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 809, 'total_tokens': 1116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTJKjG5QET3nMQqRR2a9dZxOxK8', 'finish_reason': 'stop', 'logprobs': None}, id='run-617df59e-1423-4a57-8638-ca57a6698a8b-0', usage_metadata={'input_tokens': 809, 'output_tokens': 307, 'total_tokens': 1116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "for stream in agent_executor.stream({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Machine Learning\")\n",
    "    ]\n",
    "}):\n",
    "    print(stream)\n",
    "    print(\"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2NkEZDIzgSXpMahqA3U2RkjA', 'function': {'arguments': '{\"query\":\"2020 ICC T20 World Cup winner\"}', 'name': 'WikiepdiaSearch'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 261, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTMwFblTwoT9StSh7ILkLG4YYSu', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a9668d8d-fd6b-499d-aaaa-8020bee730ed-0', tool_calls=[{'name': 'WikiepdiaSearch', 'args': {'query': '2020 ICC T20 World Cup winner'}, 'id': 'call_2NkEZDIzgSXpMahqA3U2RkjA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 261, 'output_tokens': 26, 'total_tokens': 287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n",
      "{'tools': {'messages': [ToolMessage(content=\"Page: 2024 Men's T20 World Cup\\nSummary: The 2024 ICC Men's T20 World Cup was the ninth edition of the ICC Men's T20 World Cup, co-hosted by Cricket West Indies and USA Cricket from 1 to 29 June 2024. It was the first major ICC tournament to include matches played in the United States. The West Indies had previously hosted the 2010 competition. A total of twenty teams competed in 55 matches across six venues in the West Indies, and three in the United States.\\nThe number of participants was increased from sixteen to twenty teams, including the two hosts, the top eight teams from the 2022 edition, the two highest-ranked teams in the ICC Men's T20I Team Rankings not already qualified, and eight other teams determined through regional qualifiers. Canada and Uganda qualified for the men's T20 World Cup for the first time; and the United States participated for the first time by virtue of being co-hosts.\\nEngland were the defending champions and were beaten in the semi-finals by India, who wen\", name='WikiepdiaSearch', id='76e38561-9b58-4a94-8e49-7ac83bdca195', tool_call_id='call_2NkEZDIzgSXpMahqA3U2RkjA')]}}\n",
      "***********\n",
      "{'agent': {'messages': [AIMessage(content='The information about the 2020 ICC T20 World Cup winner is not available in the search results. Would you like me to search for it using a different approach?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 517, 'total_tokens': 553, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BChTOEvaMdO2nXCaxOc7HY4XnVKUU', 'finish_reason': 'stop', 'logprobs': None}, id='run-c2387198-c370-43f9-86db-ffecf464dfaf-0', usage_metadata={'input_tokens': 517, 'output_tokens': 36, 'total_tokens': 553, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "for stream in agent_executor.stream({\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Who won the world cup in the Year 2020 in Cricket?\")\n",
    "    ]\n",
    "}):\n",
    "    print(stream)\n",
    "    print(\"***********\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
